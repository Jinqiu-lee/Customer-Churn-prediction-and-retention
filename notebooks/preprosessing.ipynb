{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = pd.read_csv(\"/Users/irisvitalee/Documents/ML-AI projects/Project1-Customer Churn/data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['Churn'] = df['Churn'].astype(str).str.strip().map({'Yes': 1, 'No': 0})\n",
    "    missing_churn = df['Churn'].isna().sum()\n",
    "    if missing_churn > 0:\n",
    "      print(f\" Warning: Found {missing_churn} rows with unknown/missing Churn values. Dropping them.\")\n",
    "      df = df[df['Churn'].notna()]\n",
    "        \n",
    "    df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "    df = df.drop(['customerID'],axis=1)\n",
    "    \n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    imputer.fit(df[['TotalCharges']])\n",
    "    df['TotalCharges'] = imputer.transform(df[['TotalCharges']])\n",
    "    \n",
    "     # train , test split\n",
    "    train_df, test_df = train_test_split(df,test_size=0.2,random_state=42)\n",
    "\n",
    "    # Identify Input columns and target col\n",
    "    target_col = 'Churn'\n",
    "    input_cols = list(df.drop(['Churn','SeniorCitizen'],axis=1))\n",
    "    \n",
    "    train_inputs = train_df[input_cols]\n",
    "    train_target = train_df[target_col]\n",
    "    test_inputs = test_df[input_cols]\n",
    "    test_target = test_df[target_col]\n",
    "        \n",
    "    numerical_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_cols = train_inputs.select_dtypes('object').columns.tolist()\n",
    "      \n",
    "      # encode categorical date \n",
    "    encoder = OneHotEncoder(sparse_output=False,handle_unknown='ignore')\n",
    "    encoder.fit(df[categorical_cols])\n",
    "    encoded_cols = list(encoder.get_feature_names_out(categorical_cols))  \n",
    "    \n",
    "    train_inputs.loc[:,encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
    "    test_inputs.loc[:,encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
    "    \n",
    "    train_inputs = train_inputs[numerical_cols + encoded_cols]\n",
    "    test_inputs = test_inputs[numerical_cols+encoded_cols]\n",
    "    \n",
    "    return numerical_cols,encoded_cols,categorical_cols,train_inputs,train_target,test_inputs,test_target\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols, enc_cols,cat_cols,X_train,y_train, X_test,y_test = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5634, 44) (5634,) (1409, 44) (1409,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack all return values\n",
    "def scaled():\n",
    "    # Scale numerical features\n",
    "    num_imputer = SimpleImputer(strategy='mean')   \n",
    "    X_train_num = num_imputer.fit_transform(X_train[num_cols])\n",
    "    X_test_num = num_imputer.transform(X_test[num_cols])\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled_num = scaler.fit_transform(X_train_num)\n",
    "    X_test_scaled_num = scaler.transform(X_test_num)\n",
    "\n",
    "    df_train_scaled_num = pd.DataFrame(X_train_scaled_num, columns=num_cols, index=X_train.index)\n",
    "    df_test_scaled_num = pd.DataFrame(X_test_scaled_num, columns=num_cols, index=X_test.index)\n",
    "    \n",
    "    # Keep encoded categorical features\n",
    "    X_train_encoded = X_train[enc_cols]\n",
    "    X_test_encoded = X_test[enc_cols]\n",
    "    \n",
    "     # Combine scaled numerical and encoded categorical features\n",
    "    X_scaled_train = pd.concat([df_train_scaled_num, X_train_encoded], axis=1)\n",
    "    X_scaled_test = pd.concat([df_test_scaled_num, X_test_encoded], axis=1)\n",
    "    \n",
    "    return X_scaled_train, X_scaled_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5634, 44) (5634,) (1409, 44) (1409,)\n"
     ]
    }
   ],
   "source": [
    "X_scaled_train, X_scaled_test, y_train, y_test = scaled()\n",
    "print(X_scaled_train.shape,y_train.shape,X_scaled_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
